theme_transparent() +
theme(axis.ticks.length = unit(0, "mm"))
print(g)
# Hexagon logo
g <- ggplot() +
geom_polygon(data = hex, aes(x, y), color = greys[8L], fill = greys[1L], size = 8) +
geom_subview(p, x = 0, y = 0, width = 1.75, height = 1.5) +
annotate(geom = "text", label = "sure", x = 0, y = 1.5 * min(big_t$y),
family = "Open Sans Light", color = greys[8L], size = 8) +
annotate(geom = "text", label = "surrogate residuals", x = 0, y = -2,
family = "Open Sans Light", color = greys[8L], size = 8) +
coord_equal(xlim = range(hex$x), ylim = range(hex$y)) +
scale_x_continuous(expand = c(0.04, 0)) +
scale_y_reverse(expand = c(0.04, 0)) +
theme_void() +
theme_transparent() +
theme(axis.ticks.length = unit(0, "mm"))
print(g)
g <- ggplot() +
geom_polygon(data = hex, aes(x, y), color = greys[8L], fill = greys[1L], size = 8) +
geom_subview(p, x = 0, y = 0, width = 1.75, height = 1.5) +
annotate(geom = "text", label = "sure", x = 0, y = 1.5 * min(big_t$y),
family = "Open Sans Light", color = greys[8L], size = 8) +
annotate(geom = "text", label = "surrogate residuals", x = 0, y = -1.5,
family = "Open Sans Light", color = greys[8L], size = 8) +
coord_equal(xlim = range(hex$x), ylim = range(hex$y)) +
scale_x_continuous(expand = c(0.04, 0)) +
scale_y_reverse(expand = c(0.04, 0)) +
theme_void() +
theme_transparent() +
theme(axis.ticks.length = unit(0, "mm"))
print(g)
g <- ggplot() +
geom_polygon(data = hex, aes(x, y), color = greys[8L], fill = greys[1L], size = 8) +
geom_subview(p, x = 0, y = 0, width = 1.75, height = 1.5) +
annotate(geom = "text", label = "sure", x = 0, y = 1.5 * min(big_t$y),
family = "Open Sans Light", color = greys[8L], size = 8) +
annotate(geom = "text", label = "surrogate residuals", x = 0, y = 0,
family = "Open Sans Light", color = greys[8L], size = 8) +
coord_equal(xlim = range(hex$x), ylim = range(hex$y)) +
scale_x_continuous(expand = c(0.04, 0)) +
scale_y_reverse(expand = c(0.04, 0)) +
theme_void() +
theme_transparent() +
theme(axis.ticks.length = unit(0, "mm"))
print(g)
g <- ggplot() +
geom_polygon(data = hex, aes(x, y), color = greys[8L], fill = greys[1L], size = 8) +
geom_subview(p, x = 0, y = 0, width = 1.75, height = 1.5) +
annotate(geom = "text", label = "sure", x = 0, y = 1.5 * min(big_t$y),
family = "Open Sans Light", color = greys[8L], size = 8) +
annotate(geom = "text", label = "surrogate residuals", x = 0, y = -0.5,
family = "Open Sans Light", color = greys[8L], size = 8) +
coord_equal(xlim = range(hex$x), ylim = range(hex$y)) +
scale_x_continuous(expand = c(0.04, 0)) +
scale_y_reverse(expand = c(0.04, 0)) +
theme_void() +
theme_transparent() +
theme(axis.ticks.length = unit(0, "mm"))
print(g)
g <- ggplot() +
geom_polygon(data = hex, aes(x, y), color = greys[8L], fill = greys[1L], size = 8) +
geom_subview(p, x = 0, y = 0, width = 1.75, height = 1.5) +
annotate(geom = "text", label = "sure", x = 0, y = 1.5 * min(big_t$y),
family = "Open Sans Light", color = greys[8L], size = 8) +
annotate(geom = "text", label = "surrogate residuals", x = 0, y = 0.5,
family = "Open Sans Light", color = greys[8L], size = 8) +
coord_equal(xlim = range(hex$x), ylim = range(hex$y)) +
scale_x_continuous(expand = c(0.04, 0)) +
scale_y_reverse(expand = c(0.04, 0)) +
theme_void() +
theme_transparent() +
theme(axis.ticks.length = unit(0, "mm"))
print(g)
# Hexagon logo
g <- ggplot() +
geom_polygon(data = hex, aes(x, y), color = greys[8L], fill = greys[1L], size = 5) +
geom_subview(p, x = 0, y = 0, width = 1.75, height = 1.5) +
annotate(geom = "text", label = "sure", x = 0, y = -0.5,
family = "Open Sans Light", color = greys[8L], size = 10) +
annotate(geom = "text", label = "surrogate residuals", x = 0, y = 0.75,
family = "Open Sans Light", color = greys[8L], size = 5) +
coord_equal(xlim = range(hex$x), ylim = range(hex$y)) +
scale_x_continuous(expand = c(0.04, 0)) +
scale_y_reverse(expand = c(0.04, 0)) +
theme_void() +
theme_transparent() +
theme(axis.ticks.length = unit(0, "mm"))
print(g)
g <- ggplot() +
geom_polygon(data = hex, aes(x, y), color = greys[8L], fill = greys[1L], size = 5) +
geom_subview(p, x = 0, y = 0, width = 1.75, height = 1.5) +
annotate(geom = "text", label = "sure", x = 0, y = -1,
family = "Open Sans Light", color = greys[8L], size = 10) +
annotate(geom = "text", label = "surrogate residuals", x = 0, y = 0.75,
family = "Open Sans Light", color = greys[8L], size = 5) +
coord_equal(xlim = range(hex$x), ylim = range(hex$y)) +
scale_x_continuous(expand = c(0.04, 0)) +
scale_y_reverse(expand = c(0.04, 0)) +
theme_void() +
theme_transparent() +
theme(axis.ticks.length = unit(0, "mm"))
print(g)
p <- autoplot(fit, what = "covariate", x = df1$x, alpha = 0.5) +
# xlab("") +
# ylab("") +
theme(axis.line = element_blank(),axis.text.x=element_blank(),
axis.text.y = element_blank(),axis.ticks=element_blank(),
axis.title.x = element_blank(),
axis.title.y = element_blank(),
legend.position = "none")
# panel.background = element_blank(),
# panel.border = element_blank(),
# panel.grid.major = element_blank(),
# panel.grid.minor = element_blank(),
# plot.background = element_blank())
print(p)
source('C:/Users/greenweb/Desktop/hex_logo.R', echo=TRUE)
source('C:/Users/greenweb/Desktop/hex_logo.R', echo=TRUE)
file.choose()
png("C:\\Users\\greenweb\\Desktop\\sure-logo.png", width = 181, height = 209, bg = "transparent")
print(g)
dev.off()
svg("C:\\Users\\greenweb\\Desktop\\sure-logo.svg", width = 181 / 72, height = 209 / 72, bg = "transparent")
print(g)
dev.off()
source('C:/Users/greenweb/Desktop/hex_logo.R', echo=TRUE)
source('C:/Users/greenweb/Desktop/hex_logo.R', echo=TRUE)
p + theme_light()
p
source('C:/Users/greenweb/Desktop/hex_logo.R', echo=TRUE)
source('C:/Users/greenweb/Desktop/hex_logo.R', echo=TRUE)
?geom_subview
source('C:/Users/greenweb/Desktop/hex_logo.R', echo=TRUE)
source('C:/Users/greenweb/Desktop/hex_logo.R', echo=TRUE)
library(nnet)
library(sure)
data(df1)
?multinom
fit <- multinom(y ~ x, data = df1)
prob <- predict(fit)
head(prob)
?predict.multinom
prob <- predict(fit, type = "raw")
prob <- predict(fit, type = "probs")
head(prob)
head(fit$fitted.values)
getJitteredResiduals <- function(object, jitter.scale, y) {
if (jitter.scale == "response") {
runif(length(y), min = y, max = y + 1) - (object$fitted.values + 0.5)
} else {
.min <- pbinom(y - 1, size = 1, prob = object$fitted.values)  # F(y-1)
.max <- pbinom(y, size = 1, prob = object$fitted.values)  # F(y)
runif(length(y), min = .min, max = .max) - 0.5  # S|Y=y - E(S|X)
}
}
res <- getJitteredResiduals(fit, "a", df1$y)
prob <- predict(fit, type = "probs")[, 1L, drop = TRUE]
getJitteredResiduals <- function(object, jitter.scale, y) {
if (jitter.scale == "response") {
runif(length(y), min = y, max = y + 1) - (prob + 0.5)
} else {
.min <- pbinom(y - 1, size = 1, prob = prob)  # F(y-1)
.max <- pbinom(y, size = 1, prob = prob)  # F(y)
runif(length(y), min = .min, max = .max) - 0.5  # S|Y=y - E(S|X)
}
}
res <- getJitteredResiduals(fit, "a", df1$y)
getJitteredResiduals <- function(object, jitter.scale, y) {
prob <- predict(object, type = "probs")[, 1L, drop = TRUE]
y <- as.integer(y) - 1
if (jitter.scale == "response") {
runif(length(y), min = y, max = y + 1) - (prob + 0.5)
} else {
.min <- pbinom(y - 1, size = 1, prob = prob)  # F(y-1)
.max <- pbinom(y, size = 1, prob = prob)  # F(y)
runif(length(y), min = .min, max = .max) - 0.5  # S|Y=y - E(S|X)
}
}
res <- getJitteredResiduals(fit, "a", df1$y)
plot(df1$x, res)
res <- getJitteredResiduals(fit, "response", df1$y)
plot(df1$x, res)
source('~/.active-rstudio-document', echo=TRUE)
fit <- multinom(y ~ x + I(x ^ 2), data = df1)
prob <- predict(fit, type = "probs")[, 1L, drop = TRUE]
getJitteredResiduals <- function(object, jitter.scale, y) {
prob <- predict(object, type = "probs")[, 1L, drop = TRUE]
y <- as.integer(y) - 1
if (jitter.scale == "response") {
runif(length(y), min = y, max = y + 1) - (prob + 0.5)
} else {
.min <- pbinom(y - 1, size = 1, prob = prob)  # F(y-1)
.max <- pbinom(y, size = 1, prob = prob)  # F(y)
runif(length(y), min = .min, max = .max) - 0.5  # S|Y=y - E(S|X)
}
}
par(mfrow = c(1, 2))
res1 <- getJitteredResiduals(fit, "probability", df1$y)
plot(df1$x, res1)
res2 <- getJitteredResiduals(fit, "response", df1$y)
plot(df1$x, res2)
data(df1)
fit <- multinom(y ~ x + I(x ^ 2), data = df1)
prob <- predict(fit, type = "probs")[, 1L, drop = TRUE]
fit
getJitteredResiduals <- function(object, jitter.scale, y) {
prob <- predict(object, type = "probs")[, 1L, drop = TRUE]
y <- as.integer(y) - 1
if (jitter.scale == "response") {
runif(length(y), min = y, max = y + 1) - (prob + 0.5)
} else {
.min <- pbinom(y - 1, size = 1, prob = prob)  # F(y-1)
.max <- pbinom(y, size = 1, prob = prob)  # F(y)
runif(length(y), min = .min, max = .max) - 0.5  # S|Y=y - E(S|X)
}
}
par(mfrow = c(1, 2))
res1 <- getJitteredResiduals(fit, "probability", df1$y)
plot(df1$x, res1)
res2 <- getJitteredResiduals(fit, "response", df1$y)
plot(df1$x, res2)
fit <- multinom(y ~ x, data = df1)
prob <- predict(fit, type = "probs")[, 1L, drop = TRUE]
getJitteredResiduals <- function(object, jitter.scale, y) {
prob <- predict(object, type = "probs")[, 1L, drop = TRUE]
y <- as.integer(y) - 1
if (jitter.scale == "response") {
runif(length(y), min = y, max = y + 1) - (prob + 0.5)
} else {
.min <- pbinom(y - 1, size = 1, prob = prob)  # F(y-1)
.max <- pbinom(y, size = 1, prob = prob)  # F(y)
runif(length(y), min = .min, max = .max) - 0.5  # S|Y=y - E(S|X)
}
}
par(mfrow = c(1, 2))
res1 <- getJitteredResiduals(fit, "probability", df1$y)
plot(df1$x, res1)
res2 <- getJitteredResiduals(fit, "response", df1$y)
plot(df1$x, res2)
?rbinom
#' @keywords internal
getResponseValues.multinom <- function(object) {
as.integer(model.response(model.frame(object))) - 1  # convert to 0, 1
}
getResponseValues.multinom(fit)
source('C:/Users/greenweb/Desktop/sure-multinom.R', echo=TRUE)
source('C:/Users/greenweb/Desktop/sure-multinom.R', echo=TRUE)
source('C:/Users/greenweb/Desktop/sure-multinom.R', echo=TRUE)
getProbs(fit)
fit
source('C:/Users/greenweb/Desktop/sure-multinom.R', echo=TRUE)
source('C:/Users/greenweb/Desktop/sure-multinom.R', echo=TRUE)
plot(df1)
devtools::install_github("AFIT-R/MODA")
################################################################################
# Setup
################################################################################
# Load required packages
library(ggplot2)
library(MASS)
library(ordinal)
library(rms)
library(VGAM)
library(sure)
data(df1)
# Fit a (correct) probit model
fit.polr <- polr(y ~ x + I(x ^ 2), data = df1, method = "probit")
# Probability-scale residuals
pres <- presid(fit.polr)
# Residual plots using the SBS residuals
p1 <- ggplot(data.frame(x = df1$x, y = pres), aes(x, y)) +
geom_point(alpha = 0.5) +
geom_smooth(color = "red", se = FALSE) +
ylab("Probability residual")
p2 <- ggplot(data.frame(y = pres), aes(sample = y)) +
stat_qq(distribution = qunif, dparams = list(min = -1, max = 1), alpha = 0.5) +
xlab("Sample quantile") +
ylab("Theoretical quantile")
# Figure ?
pdf(file = "manuscript\\quadratic-correct-sbs.pdf", width = 8, height = 4)
grid.arrange(p1, p2, ncol = 2)
dev.off()
library(PResiduals)
# Load the simulated quadratic data
data(df1)
# Fit a (correct) probit model
fit.polr <- polr(y ~ x + I(x ^ 2), data = df1, method = "probit")
# Probability-scale residuals
pres <- presid(fit.polr)
# Residual plots using the SBS residuals
p1 <- ggplot(data.frame(x = df1$x, y = pres), aes(x, y)) +
geom_point(alpha = 0.5) +
geom_smooth(color = "red", se = FALSE) +
ylab("Probability residual")
p2 <- ggplot(data.frame(y = pres), aes(sample = y)) +
stat_qq(distribution = qunif, dparams = list(min = -1, max = 1), alpha = 0.5) +
xlab("Sample quantile") +
ylab("Theoretical quantile")
# Figure ?
pdf(file = "manuscript\\quadratic-correct-sbs.pdf", width = 8, height = 4)
grid.arrange(p1, p2, ncol = 2)
dev.off()
# Surrogate residuals
set.seed(101)  # for reproducibility
sres <- resids(fit.polr)
# Residual plots using the surrogate-based residuals
p1 <- autoplot(sres, what = "covariate", x = df1$x, xlab = "x")
p2 <- autoplot(sres, what = "qq", disttribution = pnorm)
getwd()
# Residual plots using the SBS residuals
p1 <- ggplot(data.frame(x = df1$x, y = pres), aes(x, y)) +
geom_point(alpha = 0.5) +
geom_smooth(color = "red", se = FALSE) +
ylab("Probability residual")
p2 <- ggplot(data.frame(y = pres), aes(sample = y)) +
stat_qq(distribution = qunif, dparams = list(min = -1, max = 1), alpha = 0.5) +
xlab("Sample quantile") +
ylab("Theoretical quantile")
# Figure ?
pdf(file = "quadratic-correct-sbs.pdf", width = 8, height = 4)
grid.arrange(p1, p2, ncol = 2)
dev.off()
# Surrogate residuals
set.seed(101)  # for reproducibility
sres <- resids(fit.polr)
# Residual plots using the surrogate-based residuals
p1 <- autoplot(sres, what = "covariate", x = df1$x, xlab = "x")
p2 <- autoplot(sres, what = "qq", disttribution = pnorm)
# Figure ?
pdf(file = "quadratic-correct-surrogate.pdf", width = 8, height = 4)
grid.arrange(p1, p2, ncol = 2)
dev.off()
table(df1$y)
summary(1:10)
fivenum(1:10)
x <- c(5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5, 5)
hist(x)
sd(x)
var(x)
mean(x)
median(x)
IQR(x)
mad(x)
sd(rep(1, 10), rep(5, 10))
sd(c(rep(1, 10), rep(5, 10)))
sd(c(5, 10))
install.packages("ISLR")
data(Caravan)
??Caravan
head(Caravan)
head(Caravan)
library(ISLR)
head(Caravan)
library(randomForest)
fit <- randomForest(Purchase ~ ., data = Caravan, importance = TRUE)
?randomForest
fit <- randomForest(Purchase ~ ., data = Caravan, importance = TRUE, do.trace = TRUE)
library(vip)
varImpPlot(fit)
vip(fit, progress = "text", quantiles = TRUE, probs = 0:10/10)
vip(fit, progress = "text", quantiles = TRUE, probs = 0:10/10, pred.var = subset(Caravan, select = -Purchases))
vip(fit, progress = "text", quantiles = TRUE, probs = 0:10/10, pred.var = subset(Caravan, select = -Purchase))
pred.var = subset(Caravan, select = -Purchase)
pred.var
vip(fit, progress = "text", quantiles = TRUE, probs = 0:10/10, pred.var = names(subset(Caravan, select = -Purchase)))
fit
plot(fit)
head(df2)
library(sure)
head(df2)
library(ordinal)
?clm
# Fit a cumulative link model with probit link
fit.clm <- clm(y ~ x, data = df2, link = "probit")
# Obtain the SBS/probability-scale residusls
pres <- PResiduals::presid(fit.polr)
# Residual vs. covariate plots
set.seed(102)  # for reproducibility
p1 <- autoplot(fit.clm, what = "covariate", x = df2$x, xlab = "x")
p2 <-   ggplot(data.frame(x = hd$x, y = ls.res), aes(x, y)) +
geom_point(size = 2, alpha = 0.25) +
geom_smooth(col = "red", se = FALSE) +
ylab("Probability scale residual")
library(ggplot2)
library(ordinal)
# Fit a cumulative link model with probit link
fit.clm <- clm(y ~ x, data = df2, link = "probit")
# Obtain the SBS/probability-scale residusls
pres <- PResiduals::presid(fit.polr)
# Residual vs. covariate plots
set.seed(102)  # for reproducibility
p1 <- autoplot(fit.clm, what = "covariate", x = df2$x, xlab = "x")
p2 <-   ggplot(data.frame(x = hd$x, y = ls.res), aes(x, y)) +
geom_point(size = 2, alpha = 0.25) +
geom_smooth(col = "red", se = FALSE) +
ylab("Probability scale residual")
pres <- PResiduals::presid(fit.clm)
?PResiduals::presid
library(rms)
?orm
fit.orm <- orm(y ~ x, data = df2, family = "probit")
pres <- presid(fit.clm)
library(PResiduals)
set.seed(102)  # for reproducibility
p1 <- autoplot(fit.clm, what = "covariate", x = df2$x, xlab = "x")
p2 <-   ggplot(data.frame(x = hd$x, y = presid(fit.clm)), aes(x, y)) +
geom_point(size = 2, alpha = 0.25) +
geom_smooth(col = "red", se = FALSE) +
ylab("Probability scale residual")
set.seed(102)  # for reproducibility
p1 <- autoplot(fit.clm, what = "covariate", x = df2$x, xlab = "x")
p2 <-   ggplot(data.frame(x = df2$x, y = presid(fit.clm)), aes(x, y)) +
geom_point(size = 2, alpha = 0.25) +
geom_smooth(col = "red", se = FALSE) +
ylab("Probability scale residual")
set.seed(102)  # for reproducibility
p1 <- autoplot(fit.orm, what = "covariate", x = df2$x, xlab = "x")
p2 <-   ggplot(data.frame(x = df2$x, y = presid(fit.orm)), aes(x, y)) +
geom_point(size = 2, alpha = 0.25) +
geom_smooth(col = "red", se = FALSE) +
ylab("Probability scale residual")
# Residual vs. covariate plots
set.seed(102)  # for reproducibility
p1 <- autoplot(fit.orm, what = "covariate", x = df2$x, xlab = "x")
p2 <-   ggplot(data.frame(x = df2$x, y = presid(fit.orm, x = TRUE)), aes(x, y)) +
geom_point(size = 2, alpha = 0.25) +
geom_smooth(col = "red", se = FALSE) +
ylab("Probability scale residual")
set.seed(102)  # for reproducibility
p1 <- autoplot(fit.orm, what = "covariate", x = df2$x, xlab = "x")
p2 <-   ggplot(data.frame(x = df2$x, y = presid(fit.orm)), aes(x, y)) +
geom_point(size = 2, alpha = 0.25) +
geom_smooth(col = "red", se = FALSE) +
ylab("Probability scale residual")
fit.orm <- orm(y ~ x, data = df2, family = "probit", x = TRUE)
# Residual vs. covariate plots
set.seed(102)  # for reproducibility
p1 <- autoplot(fit.orm, what = "covariate", x = df2$x, xlab = "x")
p2 <-   ggplot(data.frame(x = df2$x, y = presid(fit.orm)), aes(x, y)) +
geom_point(size = 2, alpha = 0.25) +
geom_smooth(col = "red", se = FALSE) +
ylab("Probability scale residual")
grid.arrange(p1, p2, ncol = 2)
# Figure ?
pdf(file = "manuscript\\heteroscedasticity.pdf", width = 8, height = 4)
grid.arrange(p1, p2, ncol = 2)
dev.off()
pdf(file = "heteroscedasticity.pdf", width = 8, height = 4)
grid.arrange(p1, p2, ncol = 2)
dev.off()
?presid
library(bootstrap)
install.packages("bootstrap")
library(doParallel) # load the parallel backend
cl <- makeCluster(4) # use 4 workers
registerDoParallel(cl) # register the parallel backend
library(pdp)
library(xgboost)
data(boston, package = "pdp")
boston <- sapply(boston, as.numeric)
x<-as.matrix(subset(boston,,-c(cmedv)))
y<-as.matrix(subset(boston,,c(cmedv)))
dtrain <- xgb.DMatrix(data =x, label =y )
bst <- xgboost(data = dtrain, max.depth = 2, eta = 1, nthread = 2, nround = 50, objective = "reg:linear", verbose = 2)
xgb.save(bst,'bst.mod')
mod_load<-xgb.load('bst.mod')
mod_load %>% partial(train = x,pred.var = "lstat", grid.resolution = 15,parallel = TRUE) %>% pdp::plotPartial(smooth=TRUE, ylab =expression(f(lstat)), xlab = "lstat", main="Partial Dependence Plot \n -with smooth-")
mod_load
names(mod_load)
mod_load$handle
names(mod_load$handle)
names(mod_load$raw)
?xgb.load
predict.xgb
class(mod_load)
class(bst)
names(bst)
?xgboost
`xgb.parameters(bst)
))
()
''
"
<- NULL
NULL
md
)))
?xgb.save
library(doParallel) # load the parallel backend
cl <- makeCluster(4) # use 4 workers
registerDoParallel(cl) # register the parallel backend
library(pdp)
library(xgboost)
data(boston, package = "pdp")
boston <- sapply(boston, as.numeric)
x<-as.matrix(subset(boston,,-c(cmedv)))
y<-as.matrix(subset(boston,,c(cmedv)))
dtrain <- xgb.DMatrix(data =x, label =y )
bst <- xgboost(data = dtrain, max.depth = 2, eta = 1, nthread = 2, nround = 50, objective = "reg:linear", verbose = 2)
#OK
bst %>% partial(train = x,pred.var = "lstat", grid.resolution = 15,parallel = TRUE) %>%
pdp::plotPartial(smooth=TRUE, ylab =expression(f(lstat)),
xlab = "lstat", main="Partial Dependence Plot \n -with smooth-")
xgb.save(bst,'bst.mod')
mod_load<-xgb.load('bst.mod')
?xgb.save
mod_load %>% partial(train = x,pred.var = "lstat", grid.resolution = 15,parallel = TRUE) %>% pdp::plotPartial(smooth=TRUE, ylab =expression(f(lstat)), xlab = "lstat", main="Partial Dependence Plot \n -with smooth-")
#fails
mod_load %>% partial(train = x,pred.var = "lstat", grid.resolution = 15,parallel = TRUE,
type = "regression") %>%
pdp::plotPartial(smooth=TRUE, ylab =expression(f(lstat)), xlab = "lstat", main="Partial Dependence Plot \n -with smooth-")
